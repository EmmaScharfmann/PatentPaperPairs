{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "04041116-cfb6-446c-8333-cdf804ca4e90",
   "metadata": {},
   "source": [
    "This notebook provides the code to pair each PPP with a control paper (\"similar paper\") and to generate the files \"loose_twins.tsv\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5b69e81-7c0f-4d6c-b6f2-ed47ab624a4c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e049f3da",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fs01/spec1142/anaconda3/envs/patents2/lib/python3.9/site-packages/fuzzywuzzy/fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n",
      "  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n"
     ]
    }
   ],
   "source": [
    "## load packages \n",
    "from pySankey.sankey import sankey\n",
    "import pandas as pd\n",
    "import json, requests \n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from tqdm import tqdm\n",
    "import json, requests \n",
    "import time\n",
    "import unicodedata\n",
    "from metaphone import doublemetaphone\n",
    "from fuzzywuzzy import fuzz\n",
    "from difflib import SequenceMatcher\n",
    "import re\n",
    "import plotly.express as px\n",
    "from math import radians, cos, sin, asin, sqrt\n",
    "import datetime \n",
    "from datetime import date\n",
    "import psycopg2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ebab3a52-acb4-40de-a829-5f33cca13d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "## import database username and password\n",
    "main_path = \"/home/fs01/spec1142/Emma/PPPs/\"\n",
    "\n",
    "f = open(main_path + \"database.txt\", \"r\")\n",
    "user , password = f.read().split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a609794-5050-4ac6-b350-b2ad9a561be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## load PPP file \n",
    "PPPs = pd.read_csv(main_path + \"PPPs_v2.tsv\" , delimiter = \"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "45821da1-148a-4333-aef8-201fce376d6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "548315"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(PPPs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "456c3f43",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Getting all papers from the same journal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "b1285a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## getting all the PPPs journals and years the journals are publishing a PPP\n",
    "\n",
    "def get_journal(i):\n",
    "\n",
    "     \"\"\"\n",
    "    This function retrieves the publication date, venue or source, and concepts for each PPP in a list of papers from a PostgreSQL database, and stores the information in a dictionary. It also creates a separate dictionary to store the years in which each venue published papers. The dictionaries are then saved to a JSON file.\n",
    "\n",
    "    Parameters:\n",
    "    i (int): The starting index for selecting papers. (for multiprocessing)\n",
    "\n",
    "    Note:\n",
    "    - The function assumes that the `user`, `password`, `main_path`, `PPPs`, and `workers` variables are defined elsewhere in the code.\n",
    "    - The function establishes a connection to a PostgreSQL database using the `psycopg2` library and executes a SQL query to fetch the required data.\n",
    "    - The function stores the retrieved data in two dictionaries: `dic_journal`.\n",
    "    - The `dic_journal` dictionary contains the years in which each venue published papers.\n",
    "    - The function saves the `dic_journal` dictionary to a JSON file named \"journals.json\" in the specified directory.\n",
    "    \"\"\"\n",
    "\n",
    "    workers = 1 \n",
    "    \n",
    "    dic_journal = {}   \n",
    "\n",
    "\n",
    "    #establishing the connection with the database \n",
    "    conn = psycopg2.connect(\"user=\" + user + \" password=\" + password) \n",
    "    cursor = conn.cursor()\n",
    "\n",
    "\n",
    "    papers = list(set(PPPs[\"paper_id\"].tolist()))\n",
    "    index_papers = [ k for k in range(i,len(papers),workers)]\n",
    "\n",
    "    # get papers date, journal \n",
    "    for k in index_papers:\n",
    "\n",
    "\n",
    "        work_id = papers[k]\n",
    "\n",
    "\n",
    "        text = \"\"\" SELECT  publication_date , venue_or_source \n",
    "                   FROM works_OpenAlex WHERE work_id = '\"\"\"+ work_id + \"\"\"' \n",
    "                   UNION \n",
    "                   SELECT  publication_date , venue_or_source \n",
    "                   FROM works_OpenAlex3 WHERE work_id = '\"\"\"+ work_id + \"\"\"';\"\"\"\n",
    "\n",
    "\n",
    "        cursor.execute(text)  \n",
    "        res = cursor.fetchall()\n",
    "\n",
    "        if len(res) > 0: \n",
    "            line = res[0]\n",
    "\n",
    "            if line[1] != '':\n",
    "\n",
    "                venue = line[1]   \n",
    "                if line[0] != None:\n",
    "                    year = line[0].year\n",
    "                    if venue not in dic_journal: \n",
    "                        dic_journal[venue] = set()\n",
    "                    dic_journal[venue].add(year)\n",
    "\n",
    "    \n",
    "    for venue in dic_journal:\n",
    "        dic_journal[venue] = list(dic_journal[venue])\n",
    "\n",
    "    # save journal and their corresponding papers \n",
    "    import json\n",
    "    json = json.dumps(dic_journal)\n",
    "    f = open(main_path + \"PPP_analysis/journals.json\",\"w\")\n",
    "    f.write(json)\n",
    "    f.close()\n",
    "    \n",
    "    \n",
    "    \n",
    "get_journal(0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "fe13ee87",
   "metadata": {},
   "outputs": [],
   "source": [
    "## file with all PPP journals and years the journals are publishing a PPP\n",
    "\n",
    "f = open(main_path + \"PPP_analysis/journals.json\",\"r\")\n",
    "import json\n",
    "dic_journals = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "5053266c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## for each journal, get all papers, publication years and concepts. \n",
    "\n",
    "def get_papers_journal(i):\n",
    "    \"\"\"\n",
    "    This function retrieves the publication date and concepts for each paper published in a list of journals from a PostgreSQL database, and stores the information in a dictionary. The dictionary is then saved to a JSON file.\n",
    "\n",
    "    Parameters:\n",
    "    i (int): The starting index for selecting journals.\n",
    "\n",
    "    Note:\n",
    "    - The function assumes that the `user`, `password`, `main_path`, `dic_journals`, and `workers` variables are defined elsewhere in the code.\n",
    "    - The function establishes a connection to a PostgreSQL database using the `psycopg2` library and executes a SQL query to fetch the required data.\n",
    "    - The function stores the retrieved data in a dictionary `dic_papers_journals`, which contains the publication date and concepts for each paper published in each journal.\n",
    "    - The function saves the `dic_papers_journals` dictionary to a JSON file named \"dic_papers_journal_i.json\" in the specified directory, where i is the starting index for selecting journals.\n",
    "    - The function closes the database connection after fetching the data.\n",
    "    \"\"\"\n",
    "\n",
    "    workers =  1\n",
    "\n",
    "    dic_papers_journals = {} \n",
    "\n",
    "    #establishing the connection with the database \n",
    "    conn = psycopg2.connect(\"user=\" + user + \" password=\" + password) \n",
    "    cursor = conn.cursor()\n",
    "\n",
    "\n",
    "    list_journals = list(dic_journals.keys())\n",
    "    index_journal = [ k for k in range(i,len(list_journals),workers)]\n",
    "\n",
    "    ## for each journal, get works, publication date, concepts \n",
    "    for k in index_journal:\n",
    "\n",
    "\n",
    "        journal = list_journals[k]\n",
    "        dic_papers_journals[journal] = {}\n",
    "\n",
    "\n",
    "        text = \"\"\" SELECT w.work_id , w.publication_date , w.concepts \n",
    "                   FROM works_OpenAlex AS w\n",
    "                   WHERE venue_or_source = '\"\"\"+ journal + \"\"\"';\"\"\"\n",
    "                   \n",
    "\n",
    "        cursor.execute(text)  \n",
    "        res = cursor.fetchall()\n",
    "\n",
    "        for line in res:\n",
    "            work_id = line[0]\n",
    "            if work_id not in dic_papers_journals[journal]:\n",
    "                dic_papers_journals[journal][work_id] = {}\n",
    "                if line[1] != None:\n",
    "                    dic_papers_journals[journal][work_id][\"date\"] = line[1].strftime('%m-%d-%Y')\n",
    "                else:\n",
    "                    dic_papers_journals[journal][work_id][\"date\"] = None\n",
    "\n",
    "\n",
    "                if line[2] != None:\n",
    "                    concepts = set(line[2].replace(\"\\r\",\"\").split(\"#tab#\"))\n",
    "                else:\n",
    "                    concepts = set()\n",
    "                dic_papers_journals[journal][work_id][\"concepts\"]  = \", \".join(list(concepts))\n",
    "                \n",
    "    \n",
    "    ## save the data with works, date and concepts for each journal\n",
    "    import json\n",
    "    json = json.dumps(dic_papers_journals)\n",
    "    f = open(main_path + \"PPP_analysis/dic_papers_journal_\" + str(i) + \".json\",\"w\")\n",
    "    f.write(json)\n",
    "    f.close()\n",
    "    \n",
    "\n",
    "\n",
    "get_papers_journal(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff875bfb",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Identify most similar paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "7aed2ca2-a985-4cd4-9f8a-34a7ff58efdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "## file with all papers published in the same year and journal as the PPPs. \n",
    "\n",
    "f = open(main_path + \"PPP_analysis/dic_papers_journal.json\",\"r\")\n",
    "import json \n",
    "dic_papers_journals = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "80127640-8975-4409-84dd-7cd521fe6c3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████| 8580/8580 [01:21<00:00, 105.27it/s]\n"
     ]
    }
   ],
   "source": [
    "## group the papers published in the same journal by year. \n",
    "\n",
    "keys = list(dic_papers_journals.keys())\n",
    "for k in tqdm(range(12,len(dic_papers_journals))):\n",
    "    journal = keys[k]\n",
    "    dic = {}\n",
    "    for paper in dic_papers_journals[journal]:\n",
    "        if dic_papers_journals[journal][paper]['date'] != None:\n",
    "            paper_year = int(dic_papers_journals[journal][paper]['date'][-4:])\n",
    "            if paper_year not in dic:\n",
    "                dic[paper_year] = {}\n",
    "            dic[paper_year][paper] = dic_papers_journals[journal][paper]\n",
    "    dic_papers_journals[journal] = dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "36814ad9-dc07-4e81-b48b-ac31513a4416",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████| 8592/8592 [00:35<00:00, 244.66it/s]\n"
     ]
    }
   ],
   "source": [
    "## for each PPP paper published by the journal, select up to 100 random papers published the same year in the same journal \n",
    "\n",
    "import random \n",
    "\n",
    "dic_papers_same_journal_year = {}\n",
    "set_papers_PPPs = set(list(PPPs['paper_id']))\n",
    "\n",
    "for journal in tqdm(dic_papers_journals):\n",
    "\n",
    "    for year in dic_papers_journals[journal]:\n",
    "        set_papers_journal = set(list(dic_papers_journals[journal][year].keys()))\n",
    "        overlap = set_papers_journal & set_papers_PPPs\n",
    "\n",
    "        for paper in overlap:\n",
    "      \n",
    "            dic_papers_same_journal_year[paper] = {}\n",
    "            dic_papers_same_journal_year[paper]['data'] = dic_papers_journals[journal][year][paper]\n",
    "            dic_papers_same_journal_year[paper]['papers'] = []\n",
    "\n",
    "    \n",
    "            for other_paper in set_papers_journal:\n",
    "                if other_paper != paper_year:\n",
    "                    dic_papers_same_journal_year[paper]['papers'].append(other_paper)\n",
    "                if len(dic_papers_same_journal_year[paper]['papers']) >= 100:\n",
    "                    break\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "1e95035b-63ee-4a04-8898-6852b26d9eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## save up to 100 random papers published the same year in the same journal \n",
    "\n",
    "import json\n",
    "json = json.dumps(dic_papers_same_journal_year)\n",
    "f = open(main_path + \"PPP_analysis/dic_papers_same_journal_year.json\",\"w\")\n",
    "f.write(json)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94c07acc-d5ba-4523-80c4-a209e39c0964",
   "metadata": {},
   "outputs": [],
   "source": [
    "## for each PPP, select the most similar paper published the same year and in the same journal that is NOT a PPP. \n",
    "\n",
    "run PPP_analysis/control_papers.py "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "92f36cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## merge files - df_twins is the PPP twins file \n",
    "\n",
    "df_twins = pd.concat( [ pd.read_csv(main_path + \"PPP_analysis/similar_papers_\" + str(i) + \".tsv\" , sep = \"\\t\") for i in range(24) ]) \n",
    "df_twins.to_csv(main_path + \"PPP_analysis/similar_papers.tsv\", sep =\"\\t\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2db80ecf-92bc-4edb-9806-5a189bf33c8f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Additional data on the PPPs / paired paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "30c7d976-8a0e-4f43-9d5a-049bcd32d730",
   "metadata": {},
   "outputs": [],
   "source": [
    "## load PPPs\n",
    "\n",
    "PPPs = pd.read_csv(main_path + \"PPPs_v2.tsv\" , delimiter = \"\\t\")\n",
    "set_paper_id = set(list(PPPs['paper_id']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f97e7668-83ba-442a-84c7-7cac4963e710",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Papers dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "268f85ab-44e2-44f1-b006-a4f036659b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "## load twins (similar paper)\n",
    "\n",
    "loose_twins = pd.read_csv(main_path + \"PPP_analysis/similar_papers.tsv\" , delimiter = \"\\t\", index_col = 0 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "25f031c0-9303-4cb8-a943-c37c0535875d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## query the publication date of the PPP and the twin (similar paper)\n",
    "\n",
    "def get_dates_twins(i):\n",
    "\n",
    "    \"\"\"\n",
    "    This function retrieves the publication dates of twin papers from the OpenAlex database and stores them in a dictionary.\n",
    "\n",
    "    Parameters:\n",
    "    i (int): The starting index for selecting twin papers.\n",
    "\n",
    "    Note:\n",
    "    - The function assumes that the `user`, `password`, `loose_twins`, and `workers` variables are defined elsewhere in the code.\n",
    "    - The function establishes a connection to a PostgreSQL database using the `psycopg2` library and executes SQL queries to fetch the required data.\n",
    "    - The function stores the publication dates of twin papers in a dictionary `dic_dates`.\n",
    "    - The function returns the `dic_dates` dictionary.\n",
    "    \"\"\"\n",
    "\n",
    "    #establishing the connection with the database \n",
    "    conn = psycopg2.connect(\"user=\" + user + \" password=\" + password) \n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    dic_dates = {}\n",
    "\n",
    "    workers = 96\n",
    "\n",
    "    papers1 = list(set(list(loose_twins.index)))\n",
    "    papers2 = list(set(list(loose_twins['twin'])))\n",
    "    \n",
    "    index_papers1 = [ k for k in range(i,len(papers1), workers)]\n",
    "    index_papers2 = [ k for k in range(i,len(papers2), workers)]\n",
    "\n",
    "    ## get publication date of the PPPs\n",
    "    for k in index_papers1:\n",
    "        \n",
    "        work_id = papers1[k]\n",
    "        \n",
    "        dic_dates[work_id] = {}\n",
    "        \n",
    "        text = \"\"\" SELECT  w.publication_date\n",
    "               FROM works_OpenAlex AS w \n",
    "               WHERE w.work_id = '\"\"\"+ work_id + \"\"\"';\"\"\"\n",
    "    \n",
    "        \n",
    "        cursor.execute(text)\n",
    "        res = cursor.fetchall()\n",
    "                \n",
    "        if len(res) > 0:\n",
    "            dic_dates[work_id]['paper_date'] = res[0][0]\n",
    "        else:\n",
    "            dic_dates[work_id]['paper_date'] = None\n",
    "\n",
    "\n",
    "    ## get publication date of the twins \n",
    "    for k in index_papers2:\n",
    "        \n",
    "        work_id = papers2[k]\n",
    "        if pd.isna(work_id) == False:\n",
    "        \n",
    "            dic_dates[work_id] = {}\n",
    "            \n",
    "            text = \"\"\" SELECT  w.publication_date\n",
    "                   FROM works_OpenAlex AS w \n",
    "                   WHERE w.work_id = '\"\"\"+ work_id + \"\"\"';\"\"\"\n",
    "        \n",
    "            \n",
    "            cursor.execute(text)\n",
    "            res = cursor.fetchall()\n",
    "                    \n",
    "            if len(res) > 0:\n",
    "                dic_dates[work_id]['paper_date'] = res[0][0]\n",
    "            else:\n",
    "                dic_dates[work_id]['paper_date'] = None\n",
    "        else:\n",
    "            dic_dates[work_id] = {}\n",
    "            dic_dates[work_id]['paper_date'] = None\n",
    "            \n",
    "\n",
    "    return dic_dates\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "0ec44b82-9276-400d-9848-f9ba3c53b24f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## run the function get_dates_twins using 96 cpus\n",
    "\n",
    "from multiprocessing import Pool\n",
    "from functools import partial\n",
    "\n",
    "p = Pool(96)\n",
    "func = partial(get_dates_twins)\n",
    "dates = p.map(func, [ i  for i in range(96)])\n",
    "p.close()\n",
    "\n",
    "## merge results of the threads\n",
    "dic_dates = {} \n",
    "for elem in dates:\n",
    "    dic_dates = { **dic_dates , **elem}\n",
    "print(len(dic_dates))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31daaedb-08e9-437b-bef1-716c96e9fe5b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Patents dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "2d64eb4f-ad36-41aa-8ffb-c78efc2805bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## query the patent application id, grant date and application date date of the patent PPP. \n",
    "\n",
    "def get_dates_patents(i):\n",
    "\n",
    "    \"\"\"\n",
    "    This function retrieves the patent dates, application IDs, and application dates of patents from the PatentsView database and stores them in a dictionary.\n",
    "\n",
    "    Parameters:\n",
    "    i (int): The starting index for selecting patents.\n",
    "\n",
    "    Note:\n",
    "    - The function assumes that the `user`, `password`, `PPPs`, and `workers` variables are defined elsewhere in the code.\n",
    "    - The function establishes a connection to a PostgreSQL database using the `psycopg2` library and executes SQL queries to fetch the required data.\n",
    "    - The function stores the patent dates, application IDs, and application dates of patents in a dictionary `dic_dates`.\n",
    "    - The function returns the `dic_dates` dictionary.\n",
    "    \"\"\"\n",
    "\n",
    "    #establishing the connection with the database \n",
    "    conn = psycopg2.connect(\"user=\" + user + \" password=\" + password) \n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    dic_dates = {}\n",
    "\n",
    "    workers = 12\n",
    "\n",
    "    patents = list(set(list(PPPs['patent_id'])))\n",
    "    \n",
    "    index_patent = [ k for k in range(i,len(patents), workers) ]\n",
    "\n",
    "    \n",
    "    # get the application/grant date of the patents\n",
    "    for k in index_patent:\n",
    "        \n",
    "        patent_id = patents[k][3:]\n",
    "        \n",
    "        dic_dates[patent_id] = {}\n",
    "        \n",
    "        text = \"\"\" SELECT  p.patent_date , a.application_id, a.filing_date\n",
    "               FROM patents_PatentsView AS p \n",
    "               LEFT JOIN applications_PatentsView AS a ON p.patent_id = a.patent_id\n",
    "               WHERE p.patent_id = '\"\"\"+ str(patent_id) + \"\"\"';\"\"\"\n",
    "    \n",
    "        cursor.execute(text)\n",
    "        res = cursor.fetchall()\n",
    "                \n",
    "        if len(res) > 0:\n",
    "            dic_dates[patent_id]['patent_date'] = res[0][0]\n",
    "            dic_dates[patent_id]['application_id'] = res[0][1]\n",
    "            dic_dates[patent_id]['application_date'] = res[0][2]\n",
    "        else:\n",
    "            dic_dates[patent_id]['patent_date'] = None\n",
    "            dic_dates[patent_id]['application_id'] = None\n",
    "            dic_dates[patent_id]['application_date'] = None\n",
    "    \n",
    "    return dic_dates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "d02df5a2-924a-4a95-a841-93df2ee89edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "## run the function get_dates_patents using 12 cpus\n",
    "\n",
    "from multiprocessing import Pool\n",
    "from functools import partial\n",
    "\n",
    "p = Pool(12)\n",
    "func = partial(get_dates_patents)\n",
    "dates = p.map(func, [ i  for i in range(12)])\n",
    "p.close()\n",
    "\n",
    "\n",
    "## merge results of the threads\n",
    "dic_dates_patents = {} \n",
    "for elem in dates:\n",
    "    dic_dates_patents = { **dic_dates_patents , **elem}\n",
    "print(len(dic_dates_patents))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b16664d-2bc1-441b-8de5-2e1808436627",
   "metadata": {},
   "source": [
    "### Add pair id, dates and confidence score to the file and save file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "641ce804-b2b7-43e6-baeb-98afb19c6e84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>twin</th>\n",
       "      <th>score</th>\n",
       "      <th>paper_id</th>\n",
       "      <th>patent_id</th>\n",
       "      <th>PPP_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>329497</th>\n",
       "      <td>07-15-2015</td>\n",
       "      <td>W2056326110</td>\n",
       "      <td>0.427760</td>\n",
       "      <td>W1578801066</td>\n",
       "      <td>US-9786832</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110398</th>\n",
       "      <td>06-20-2006</td>\n",
       "      <td>W582671889</td>\n",
       "      <td>0.633810</td>\n",
       "      <td>W2249867704</td>\n",
       "      <td>US-8778608</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>532744</th>\n",
       "      <td>03-17-2015</td>\n",
       "      <td>W2002262929</td>\n",
       "      <td>0.427257</td>\n",
       "      <td>W2040274814</td>\n",
       "      <td>US-11099263</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>332594</th>\n",
       "      <td>03-22-2010</td>\n",
       "      <td>W2053503785</td>\n",
       "      <td>0.445780</td>\n",
       "      <td>W2022201375</td>\n",
       "      <td>US-8394762</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304587</th>\n",
       "      <td>03-01-1988</td>\n",
       "      <td>W2064598121</td>\n",
       "      <td>0.551622</td>\n",
       "      <td>W1972554422</td>\n",
       "      <td>US-4990291</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286001</th>\n",
       "      <td>1991-09-01</td>\n",
       "      <td>W4242375445</td>\n",
       "      <td>0.199821</td>\n",
       "      <td>W4245219720</td>\n",
       "      <td>US-5191616</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286006</th>\n",
       "      <td>1991-09-01</td>\n",
       "      <td>W4242375445</td>\n",
       "      <td>0.199821</td>\n",
       "      <td>W4245219720</td>\n",
       "      <td>US-5009281</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286013</th>\n",
       "      <td>1991-09-01</td>\n",
       "      <td>W4242375445</td>\n",
       "      <td>0.199821</td>\n",
       "      <td>W4245219720</td>\n",
       "      <td>US-4987564</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286020</th>\n",
       "      <td>1991-09-01</td>\n",
       "      <td>W4242375445</td>\n",
       "      <td>0.199821</td>\n",
       "      <td>W4245219720</td>\n",
       "      <td>US-4989187</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286025</th>\n",
       "      <td>1991-09-01</td>\n",
       "      <td>W4242375445</td>\n",
       "      <td>0.199821</td>\n",
       "      <td>W4245219720</td>\n",
       "      <td>US-5009280</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>548315 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              date         twin     score     paper_id    patent_id  PPP_score\n",
       "329497  07-15-2015  W2056326110  0.427760  W1578801066   US-9786832          1\n",
       "110398  06-20-2006   W582671889  0.633810  W2249867704   US-8778608          2\n",
       "532744  03-17-2015  W2002262929  0.427257  W2040274814  US-11099263          2\n",
       "332594  03-22-2010  W2053503785  0.445780  W2022201375   US-8394762          4\n",
       "304587  03-01-1988  W2064598121  0.551622  W1972554422   US-4990291          3\n",
       "...            ...          ...       ...          ...          ...        ...\n",
       "286001  1991-09-01  W4242375445  0.199821  W4245219720   US-5191616          1\n",
       "286006  1991-09-01  W4242375445  0.199821  W4245219720   US-5009281          1\n",
       "286013  1991-09-01  W4242375445  0.199821  W4245219720   US-4987564          1\n",
       "286020  1991-09-01  W4242375445  0.199821  W4245219720   US-4989187          1\n",
       "286025  1991-09-01  W4242375445  0.199821  W4245219720   US-5009280          1\n",
       "\n",
       "[548315 rows x 6 columns]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## merge twin file and PPPs\n",
    "\n",
    "data = loose_twins.merge(PPPs[['paper_id','patent_id', 'PPP_score']], left_index = True, right_on = 'paper_id', how = 'outer')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "8a7619b8-cc1a-4949-a663-8bb31a7988ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████| 548315/548315 [00:44<00:00, 12297.75it/s]\n"
     ]
    }
   ],
   "source": [
    "## generate flat file with all the relevant info \n",
    "\n",
    "pair = 0 \n",
    "k = 0 \n",
    "dic_loose_twins = {}\n",
    "\n",
    "np_data = data[['paper_id', 'twin', 'patent_id', 'score','PPP_score' ]].to_numpy()\n",
    "\n",
    "for elem in tqdm(np_data): \n",
    "    paper_id , twin , patent_id , score,PPP_score  = elem\n",
    "    \n",
    "    dic_loose_twins[k] = {}\n",
    "    dic_loose_twins[k]['paper_id'] = paper_id\n",
    "    dic_loose_twins[k]['patent_id'] = patent_id\n",
    "    dic_loose_twins[k]['pair_id'] = pair\n",
    "    dic_loose_twins[k]['twin_score'] = score\n",
    "    dic_loose_twins[k]['PPP'] = 1\n",
    "    dic_loose_twins[k]['PPP_score'] = PPP_score\n",
    "    dic_loose_twins[k]['paper_date'] = dic_dates[paper_id]['paper_date']\n",
    "    dic_loose_twins[k]['patent_date'] = dic_dates_patents[patent_id[3:]]['patent_date']\n",
    "    dic_loose_twins[k]['application_id'] = dic_dates_patents[patent_id[3:]]['application_id']\n",
    "    dic_loose_twins[k]['application_date'] = dic_dates_patents[patent_id[3:]]['application_date']\n",
    "    k += 1\n",
    "\n",
    "    dic_loose_twins[k] = {}\n",
    "    dic_loose_twins[k]['paper_id'] = twin\n",
    "    dic_loose_twins[k]['patent_id'] = patent_id\n",
    "    dic_loose_twins[k]['pair_id'] = pair\n",
    "    dic_loose_twins[k]['twin_score'] = score\n",
    "    dic_loose_twins[k]['PPP'] = 0\n",
    "    dic_loose_twins[k]['PPP_score'] = PPP_score\n",
    "    if pd.isna(twin) == False:\n",
    "        dic_loose_twins[k]['paper_date'] = dic_dates[twin]['paper_date']\n",
    "    else:\n",
    "        dic_loose_twins[k]['paper_date'] = None\n",
    "    dic_loose_twins[k]['patent_date'] = dic_dates_patents[patent_id[3:]]['patent_date']\n",
    "    dic_loose_twins[k]['application_id'] = dic_dates_patents[patent_id[3:]]['application_id']\n",
    "    dic_loose_twins[k]['application_date'] = dic_dates_patents[patent_id[3:]]['application_date']\n",
    "    k += 1\n",
    "    pair += 1\n",
    "    \n",
    "df_loose_twins = pd.DataFrame(dic_loose_twins).T\n",
    "df_loose_twins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "448a35e7-cc71-4994-bfdc-897c7081ff4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## add patent's publication date (if exists) \n",
    "\n",
    "publication_dates = pd.read_csv(main_path + \"published_application_small.tsv\", index_col = 0 )\n",
    "publication_dates = publication_dates.drop_duplicates('application_id')\n",
    "df_loose_twins = df_loose_twins.merge(publication_dates, on ='application_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "c6120d2c-c981-4d6f-87f7-facc0b13d9dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "## save the twin file \n",
    "\n",
    "df_loose_twins.to_csv(main_path + \"PPP_analysis/loose_twins.tsv\", index = False, sep = \"\\t\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
